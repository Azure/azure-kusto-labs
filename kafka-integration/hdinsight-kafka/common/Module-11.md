

# About

This module covers creating a Databricks cluster and pinning it.  We will use Spark Structured Streaming to stream data to Kafka in a subsequent module.<br>

Navigate to your Databricks workspace.


### 1. Click on clusters
![CreateStorage01](images/04-databricks-08.png)
<br>
<hr>
<br>

### 2. Click on create clusters
![CreateStorage02](images/04-databricks-09.png)
<br>
<hr>
<br>

### 3. Enter a name, pick the number of nodes, click on start 
![CreateStorage03](images/04-databricks-10.png)
<br>
<hr>
<br>


### 4. Pin the cluster, so its metadata is persisted indefinitely; Otherwise if you dont use your workspace, and dont fire up your cluster for a few weeks, the cluster definition is deleted permanently.
![CreateStorage05](images/04-databricks-11.png)
<br>
<hr>
<br>


This concludes the module.<br>
[Return to the menu](https://github.com/anagha-microsoft/adx-kafkaConnect-hol/tree/master/hdi-standalone-nonesp#lets-get-started)
